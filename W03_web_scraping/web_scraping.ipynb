{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Web Scraping</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../image/text_DALLE.jpeg\" width=30% align=\"right\" style=\"in-line\">\n",
    "\n",
    ">*Data is like garbage.*\n",
    ">\n",
    ">*You’d better know what you are going to do with it before you collect it.*\n",
    ">\n",
    ">— Mark Twain ? ( source: [Forbes](https://www.forbes.com/councils/forbestechcouncil/2023/05/09/the-delta-between-trust-and-usability-where-data-management-still-falls-short/) )\n",
    "\n",
    "<img src=\"../image/quote1_ChatGPT.png\" width=70% align=\"left\" style=\"in-line\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T08:33:09.252271Z",
     "start_time": "2022-04-01T08:33:09.160011Z"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. Web page basics (see slides)\n",
    "2. Web scraping with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## Agneda 2. Web scraping with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes webs scraping can be really easy, other times it can be complicated. \n",
    "\n",
    "- Easy: static HTML\n",
    "- Hard: HTML and CSS\n",
    "- Harder: Javascript - Often requires a \"Headless\" web browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the web scraping. We will collect some news regarding mobility and transport.\n",
    "\n",
    "This is the website: [European Commission - Mobility and Transport News](https://transport.ec.europa.eu/news-events/news_en?page=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x1F4D6; **<font color=teal>WHAT WE HAVE LEARNED: </font>Legal and ethical considerations** \n",
    "* **Terms of Use:** The European Commission allows the reuse of its content under certain conditions.\n",
    ">Unless otherwise indicated (e.g. in individual copyright notices), content owned by the EU on this website is licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) licence. This means that reuse is allowed, provided appropriate credit is given and changes are indicated.\n",
    "\n",
    "     For educational purposes, reuse is usually permitted. Review [the Legal Notice](https://commission.europa.eu/legal-notice_en) to ensure compliance.\n",
    "     \n",
    "\n",
    "* **Robots.txt:** Check [the website's robots.txt](https://transport.ec.europa.eu/robots.txt) file to see any disallowed paths. We can see that https://transport.ec.europa.eu/news-events is not among the disallowed paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a library called `requests` to  download web pages. The `requests` will make a [GET request](https://en.wikipedia.org/wiki/HTTP#Request_methods) to a web server, which will download the HTML contents of a given web page for us. And we will use a library called `BeautifulSoup` to parse the HTML document.\n",
    "\n",
    "&#x270A; **<font color=firebrick>DO THIS: </font> Run the cell below to check if you have the libraries installed. If not, install them now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:40:04.315153Z",
     "start_time": "2024-10-29T20:40:04.125061Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:40:06.149527Z",
     "start_time": "2024-10-29T20:40:06.140036Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://transport.ec.europa.eu/news-events/news_en?page=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:40:14.169157Z",
     "start_time": "2024-10-29T20:40:14.044942Z"
    }
   },
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:40:15.755592Z",
     "start_time": "2024-10-29T20:40:15.744271Z"
    }
   },
   "outputs": [],
   "source": [
    "print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running our request, we get a Response object. This object has a status code, which shows us if the page was downloaded successfully. A status code of 200 means that the page was downloaded successfully.\n",
    "\n",
    "&#x1F4A1; **HTTP status codes** (Source: [wikipedia](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes))\n",
    "\n",
    ">* 1xx informational response – the request was received, continuing process\n",
    ">* 2xx successful – the request was successfully received, understood, and accepted\n",
    ">* 3xx redirection – further action needs to be taken in order to complete the request\n",
    ">* 4xx client error – the request contains bad syntax or cannot be fulfilled\n",
    ">* 5xx server error – the server failed to fulfil an apparently valid request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use `BeautifulSoup` to parse the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:40:48.365846Z",
     "start_time": "2024-10-29T20:40:48.324015Z"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T09:57:16.844472Z",
     "start_time": "2024-09-21T09:57:16.843056Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dir(soup)\n",
    "# help(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:40:56.766084Z",
     "start_time": "2024-10-29T20:40:56.733680Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print out the HTML content of the page\n",
    "# print(soup)\n",
    "print(soup.prettify()) #format the page nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:30:33.784343Z",
     "start_time": "2024-09-20T14:30:33.772452Z"
    }
   },
   "source": [
    "The task now is to **locate the specific content that we want to scrape**. You can either do it by a quick search of keywords, or view the page structure in a browser (for example: in Chrome by clicking `View` -> `Developer` -> `Inspect Elements`).\n",
    "\n",
    "Search keyboard shortcut: \n",
    "* Windows: `Ctrl` + `f`\n",
    "* Mac: `command` + `f`\n",
    "\n",
    "\n",
    "Once locate the content, look for the tag and attribute of the target element.\n",
    "\n",
    "&#x1F4D6; **<font color=teal>WHAT WE HAVE LEARNED: </font> HTML tags and attributes**\n",
    "\n",
    "<img src=\"../image/HTML_element.png\" width=50% align=\"left\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There could be more than one way to locate the target element. \n",
    "\n",
    "&#x1F4A1; **HTML elements:** [documentation](https://developer.mozilla.org/en-US/docs/Web/HTML/Element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:42:54.183549Z",
     "start_time": "2024-10-29T20:42:54.168372Z"
    }
   },
   "outputs": [],
   "source": [
    "news = soup.find_all(\"div\", class_=\"ecl-content-item-block__item\")\n",
    "#news = soup.find_all(\"article\", class_=\"ecl-content-item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:42:55.706979Z",
     "start_time": "2024-10-29T20:42:55.691797Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(news)\n",
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:42:58.521023Z",
     "start_time": "2024-10-29T20:42:58.510691Z"
    }
   },
   "outputs": [],
   "source": [
    "print(news[0]) # the first news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:49:03.715748Z",
     "start_time": "2024-10-29T20:49:03.708275Z"
    }
   },
   "outputs": [],
   "source": [
    "#copy paste it in a Markdown cell here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T20:44:53.252229Z",
     "start_time": "2024-10-29T20:44:53.239290Z"
    }
   },
   "outputs": [],
   "source": [
    "# a for loop to get all the titles\n",
    "for item in news:\n",
    "    title = item.find(\"a\", class_=\"ecl-link ecl-link--standalone\")\n",
    "    print(title.get_text())\n",
    "    print(\"====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note to myself: go back to the slides before the big task.\n",
    "\n",
    "&#x270A; **<font color=firebrick>DO THIS: </font>** Here is an example project. We would like to find out what the European Union has done recently (let's say since 2023) to advance sustainable mobility and transport. One possible data source is the news we just scraped, but we need more information other than the title of the news.\n",
    "\n",
    "So now please write some code to collect **the date, the title, the short description, the news type, and the link to the full text** of all news in 2023. Save the data to a **csv** file.\n",
    "\n",
    "Here are some tips:\n",
    "1. How many pages do you need to scrape? Observe how the web addresses change between the first page and the second.\n",
    "2. Remember we have talked about **avoid overloading servers** in ethics. Make sure to use `time.sleep()`.\n",
    "3. Maybe AI tools such as ChatGPT can help. But you need to make sure its solution works.\n",
    "\n",
    "If you would like to challenge yourself, see if you can scrape the full text (not the short description) of the news. Try with one or two pieces of news would be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T09:53:17.231100Z",
     "start_time": "2024-10-02T09:53:17.216536Z"
    }
   },
   "outputs": [],
   "source": [
    "# the extra packages you will need\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T09:57:16.905927Z",
     "start_time": "2024-09-21T09:57:16.904094Z"
    }
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### Congratulations, we are done!\n",
    "\n",
    "This notebook is written by [Meng Cai](https://www.verkehr.tu-darmstadt.de/vv/das_institut_ivv/team_ivv/wissenschaftliche_mitarbeiter_doktoranden/meng_cai/standardseite_204.de.jsp), Technical University of Darmstadt. Special thanks to [Dirk Colbry](https://icer.msu.edu/contact-directory/Dirk-Colbry) for sharing his course materials on this topic. This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>.\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
